{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2e041b-9f77-43a1-97b1-afb38fda452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a1cbbf-3802-4ec5-a6d1-22bb9a4bd356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "myTransform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class config:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    lr = 3e-4\n",
    "    zDim = 128\n",
    "    imageDim = 28*28*1\n",
    "    batchSize = 32\n",
    "    numEpochs = 100\n",
    "    logstep = 625\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b94fa5-cc48-41b5-a0d9-ef1d5072b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading MNIST DS\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(f\"\\nLoading MNIST DS\")\n",
    "dataset = datasets.MNIST(root=\"dataset/\",\n",
    "                         transform=myTransform,\n",
    "                         download=True)\n",
    "loader = DataLoader(dataset,\n",
    "                    batch_size=config.batchSize,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3efd19-41a4-4e08-be3c-ff15c4efd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, infeatures, hiddenDim=512, lr=0.01):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(infeatures, hiddenDim),\n",
    "            nn.LeakyReLU(negative_slope=lr),\n",
    "            nn.Linear(hiddenDim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7466a123-0b92-44bf-b4b6-b4b65e2cdf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, zDim, imageDim, hiddenDim=512):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(zDim, hiddenDim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hiddenDim, imageDim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "# Create discriminator and generator instances\n",
    "discriminator = Discriminator(config.imageDim).to(config.device)\n",
    "generator = Generator(config.zDim, config.imageDim).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f29be64-1e39-4379-938c-33fbfad1c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed Noise\n",
    "fixedNoise = torch.randn((config.batchSize, config.zDim)).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc65dd66-c775-4341-b06f-b0d8baa1493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting Optimizers\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print(f\"\\nSetting Optimizers\")\n",
    "optDisc = optim.Adam(discriminator.parameters(), lr=config.lr)\n",
    "optGen = optim.Adam(generator.parameters(), lr=config.lr)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# Initialize SummaryWriters\n",
    "writerFake = SummaryWriter(f\"C:\\\\Users\\\\raksh\\\\OneDrive\\\\Documents\\\\DL_Writer\\\\fake1\")\n",
    "writerReal = SummaryWriter(f\"C:\\\\Users\\\\raksh\\\\OneDrive\\\\Documents\\\\DL_Writer\\\\real1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96f6722-a1a7-4eca-9a67-f54d485de334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started Training and visualization...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [0/100] Batch 0/1875                 Loss Disc: 0.6641, Loss Gen: 0.7090\n",
      "Epoch [0/100] Batch 625/1875                 Loss Disc: 0.2328, Loss Gen: 1.7007\n",
      "Epoch [0/100] Batch 1250/1875                 Loss Disc: 0.3253, Loss Gen: 1.5002\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [1/100] Batch 0/1875                 Loss Disc: 0.6990, Loss Gen: 0.9570\n",
      "Epoch [1/100] Batch 625/1875                 Loss Disc: 0.6054, Loss Gen: 1.4491\n",
      "Epoch [1/100] Batch 1250/1875                 Loss Disc: 0.5451, Loss Gen: 0.9828\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [2/100] Batch 0/1875                 Loss Disc: 0.5516, Loss Gen: 1.1579\n",
      "Epoch [2/100] Batch 625/1875                 Loss Disc: 0.3073, Loss Gen: 2.1936\n",
      "Epoch [2/100] Batch 1250/1875                 Loss Disc: 0.3679, Loss Gen: 1.8044\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [3/100] Batch 0/1875                 Loss Disc: 0.2821, Loss Gen: 1.8233\n",
      "Epoch [3/100] Batch 625/1875                 Loss Disc: 0.4873, Loss Gen: 1.3857\n",
      "Epoch [3/100] Batch 1250/1875                 Loss Disc: 0.2549, Loss Gen: 2.0671\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [4/100] Batch 0/1875                 Loss Disc: 0.7155, Loss Gen: 1.0751\n",
      "Epoch [4/100] Batch 625/1875                 Loss Disc: 0.1473, Loss Gen: 2.3513\n",
      "Epoch [4/100] Batch 1250/1875                 Loss Disc: 0.2219, Loss Gen: 3.3227\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [5/100] Batch 0/1875                 Loss Disc: 0.2575, Loss Gen: 2.9100\n",
      "Epoch [5/100] Batch 625/1875                 Loss Disc: 0.3824, Loss Gen: 2.0361\n",
      "Epoch [5/100] Batch 1250/1875                 Loss Disc: 0.2507, Loss Gen: 2.5146\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [6/100] Batch 0/1875                 Loss Disc: 0.2079, Loss Gen: 2.3882\n",
      "Epoch [6/100] Batch 625/1875                 Loss Disc: 0.5204, Loss Gen: 1.6170\n",
      "Epoch [6/100] Batch 1250/1875                 Loss Disc: 0.6406, Loss Gen: 1.3344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [7/100] Batch 0/1875                 Loss Disc: 0.7020, Loss Gen: 2.0142\n",
      "Epoch [7/100] Batch 625/1875                 Loss Disc: 0.6784, Loss Gen: 1.7848\n",
      "Epoch [7/100] Batch 1250/1875                 Loss Disc: 0.2757, Loss Gen: 2.7197\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [8/100] Batch 0/1875                 Loss Disc: 0.5949, Loss Gen: 1.7954\n",
      "Epoch [8/100] Batch 625/1875                 Loss Disc: 0.3806, Loss Gen: 2.5233\n",
      "Epoch [8/100] Batch 1250/1875                 Loss Disc: 0.6496, Loss Gen: 1.5804\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [9/100] Batch 0/1875                 Loss Disc: 0.4127, Loss Gen: 2.3592\n",
      "Epoch [9/100] Batch 625/1875                 Loss Disc: 0.5763, Loss Gen: 2.4112\n",
      "Epoch [9/100] Batch 1250/1875                 Loss Disc: 0.6723, Loss Gen: 2.1426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [10/100] Batch 0/1875                 Loss Disc: 0.5084, Loss Gen: 1.6425\n",
      "Epoch [10/100] Batch 625/1875                 Loss Disc: 0.3660, Loss Gen: 1.6937\n",
      "Epoch [10/100] Batch 1250/1875                 Loss Disc: 0.3370, Loss Gen: 2.1702\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [11/100] Batch 0/1875                 Loss Disc: 0.5907, Loss Gen: 2.0202\n",
      "Epoch [11/100] Batch 625/1875                 Loss Disc: 0.4570, Loss Gen: 1.5755\n",
      "Epoch [11/100] Batch 1250/1875                 Loss Disc: 0.6485, Loss Gen: 2.0688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [12/100] Batch 0/1875                 Loss Disc: 0.3593, Loss Gen: 2.4285\n",
      "Epoch [12/100] Batch 625/1875                 Loss Disc: 0.6320, Loss Gen: 2.4152\n",
      "Epoch [12/100] Batch 1250/1875                 Loss Disc: 0.4972, Loss Gen: 1.6027\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [13/100] Batch 0/1875                 Loss Disc: 0.4843, Loss Gen: 1.1169\n",
      "Epoch [13/100] Batch 625/1875                 Loss Disc: 0.2841, Loss Gen: 2.5738\n",
      "Epoch [13/100] Batch 1250/1875                 Loss Disc: 0.3665, Loss Gen: 2.3344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [14/100] Batch 0/1875                 Loss Disc: 0.3756, Loss Gen: 2.1151\n",
      "Epoch [14/100] Batch 625/1875                 Loss Disc: 0.3638, Loss Gen: 3.1371\n",
      "Epoch [14/100] Batch 1250/1875                 Loss Disc: 0.4233, Loss Gen: 2.2402\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [15/100] Batch 0/1875                 Loss Disc: 0.5481, Loss Gen: 1.6301\n",
      "Epoch [15/100] Batch 625/1875                 Loss Disc: 0.5440, Loss Gen: 1.9276\n",
      "Epoch [15/100] Batch 1250/1875                 Loss Disc: 0.5651, Loss Gen: 2.1981\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [16/100] Batch 0/1875                 Loss Disc: 0.4562, Loss Gen: 2.9907\n",
      "Epoch [16/100] Batch 625/1875                 Loss Disc: 0.3426, Loss Gen: 1.8421\n",
      "Epoch [16/100] Batch 1250/1875                 Loss Disc: 0.4200, Loss Gen: 3.1737\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [17/100] Batch 0/1875                 Loss Disc: 0.4475, Loss Gen: 1.8171\n",
      "Epoch [17/100] Batch 625/1875                 Loss Disc: 0.3832, Loss Gen: 2.1127\n",
      "Epoch [17/100] Batch 1250/1875                 Loss Disc: 0.4992, Loss Gen: 2.3921\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [18/100] Batch 0/1875                 Loss Disc: 0.5653, Loss Gen: 1.9749\n",
      "Epoch [18/100] Batch 625/1875                 Loss Disc: 0.3462, Loss Gen: 1.7405\n",
      "Epoch [18/100] Batch 1250/1875                 Loss Disc: 0.4886, Loss Gen: 2.3787\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [19/100] Batch 0/1875                 Loss Disc: 0.3102, Loss Gen: 2.8853\n",
      "Epoch [19/100] Batch 625/1875                 Loss Disc: 0.3751, Loss Gen: 3.7128\n",
      "Epoch [19/100] Batch 1250/1875                 Loss Disc: 0.3300, Loss Gen: 3.5472\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [20/100] Batch 0/1875                 Loss Disc: 0.6983, Loss Gen: 1.4284\n",
      "Epoch [20/100] Batch 625/1875                 Loss Disc: 0.5720, Loss Gen: 1.6648\n",
      "Epoch [20/100] Batch 1250/1875                 Loss Disc: 0.5551, Loss Gen: 2.5160\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [21/100] Batch 0/1875                 Loss Disc: 0.7115, Loss Gen: 2.3744\n",
      "Epoch [21/100] Batch 625/1875                 Loss Disc: 0.7795, Loss Gen: 1.2824\n",
      "Epoch [21/100] Batch 1250/1875                 Loss Disc: 0.5071, Loss Gen: 1.8018\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [22/100] Batch 0/1875                 Loss Disc: 0.3803, Loss Gen: 2.0617\n",
      "Epoch [22/100] Batch 625/1875                 Loss Disc: 0.4217, Loss Gen: 2.0968\n",
      "Epoch [22/100] Batch 1250/1875                 Loss Disc: 0.5235, Loss Gen: 2.4040\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [23/100] Batch 0/1875                 Loss Disc: 0.2078, Loss Gen: 3.2140\n",
      "Epoch [23/100] Batch 625/1875                 Loss Disc: 0.3756, Loss Gen: 2.4559\n",
      "Epoch [23/100] Batch 1250/1875                 Loss Disc: 0.4246, Loss Gen: 2.8637\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [24/100] Batch 0/1875                 Loss Disc: 0.4912, Loss Gen: 2.1139\n",
      "Epoch [24/100] Batch 625/1875                 Loss Disc: 0.5152, Loss Gen: 2.1422\n",
      "Epoch [24/100] Batch 1250/1875                 Loss Disc: 0.5261, Loss Gen: 1.9944\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [25/100] Batch 0/1875                 Loss Disc: 0.4963, Loss Gen: 1.6912\n",
      "Epoch [25/100] Batch 625/1875                 Loss Disc: 0.6981, Loss Gen: 1.2883\n",
      "Epoch [25/100] Batch 1250/1875                 Loss Disc: 0.3458, Loss Gen: 2.1253\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [26/100] Batch 0/1875                 Loss Disc: 0.3060, Loss Gen: 2.7807\n",
      "Epoch [26/100] Batch 625/1875                 Loss Disc: 0.4827, Loss Gen: 3.0963\n",
      "Epoch [26/100] Batch 1250/1875                 Loss Disc: 0.3851, Loss Gen: 3.3236\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [27/100] Batch 0/1875                 Loss Disc: 0.3026, Loss Gen: 3.3792\n",
      "Epoch [27/100] Batch 625/1875                 Loss Disc: 0.3135, Loss Gen: 3.0815\n",
      "Epoch [27/100] Batch 1250/1875                 Loss Disc: 0.3783, Loss Gen: 1.8570\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [28/100] Batch 0/1875                 Loss Disc: 0.4743, Loss Gen: 1.7797\n",
      "Epoch [28/100] Batch 625/1875                 Loss Disc: 0.7024, Loss Gen: 1.4635\n",
      "Epoch [28/100] Batch 1250/1875                 Loss Disc: 0.4626, Loss Gen: 1.7388\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [29/100] Batch 0/1875                 Loss Disc: 0.4619, Loss Gen: 1.8574\n",
      "Epoch [29/100] Batch 625/1875                 Loss Disc: 0.5288, Loss Gen: 1.6805\n",
      "Epoch [29/100] Batch 1250/1875                 Loss Disc: 0.4782, Loss Gen: 1.8412\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [30/100] Batch 0/1875                 Loss Disc: 0.4512, Loss Gen: 2.7805\n",
      "Epoch [30/100] Batch 625/1875                 Loss Disc: 0.3050, Loss Gen: 3.0722\n",
      "Epoch [30/100] Batch 1250/1875                 Loss Disc: 0.4607, Loss Gen: 2.1199\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [31/100] Batch 0/1875                 Loss Disc: 0.5547, Loss Gen: 1.8416\n",
      "Epoch [31/100] Batch 625/1875                 Loss Disc: 0.5813, Loss Gen: 1.9048\n",
      "Epoch [31/100] Batch 1250/1875                 Loss Disc: 0.6185, Loss Gen: 1.4675\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [32/100] Batch 0/1875                 Loss Disc: 0.6230, Loss Gen: 1.9549\n",
      "Epoch [32/100] Batch 625/1875                 Loss Disc: 0.4281, Loss Gen: 2.2112\n",
      "Epoch [32/100] Batch 1250/1875                 Loss Disc: 0.5758, Loss Gen: 2.3881\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [33/100] Batch 0/1875                 Loss Disc: 0.4771, Loss Gen: 2.0765\n",
      "Epoch [33/100] Batch 625/1875                 Loss Disc: 0.3829, Loss Gen: 2.0059\n",
      "Epoch [33/100] Batch 1250/1875                 Loss Disc: 0.4159, Loss Gen: 2.4821\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [34/100] Batch 0/1875                 Loss Disc: 0.4005, Loss Gen: 2.8114\n",
      "Epoch [34/100] Batch 625/1875                 Loss Disc: 0.3645, Loss Gen: 2.1923\n",
      "Epoch [34/100] Batch 1250/1875                 Loss Disc: 0.3127, Loss Gen: 2.0712\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [35/100] Batch 0/1875                 Loss Disc: 0.4709, Loss Gen: 1.7179\n",
      "Epoch [35/100] Batch 625/1875                 Loss Disc: 0.5151, Loss Gen: 2.2412\n",
      "Epoch [35/100] Batch 1250/1875                 Loss Disc: 0.4148, Loss Gen: 1.8846\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [36/100] Batch 0/1875                 Loss Disc: 0.5931, Loss Gen: 1.4310\n",
      "Epoch [36/100] Batch 625/1875                 Loss Disc: 0.4735, Loss Gen: 1.8609\n",
      "Epoch [36/100] Batch 1250/1875                 Loss Disc: 0.4912, Loss Gen: 1.9188\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [37/100] Batch 0/1875                 Loss Disc: 0.3792, Loss Gen: 2.1629\n",
      "Epoch [37/100] Batch 625/1875                 Loss Disc: 0.5933, Loss Gen: 1.9552\n",
      "Epoch [37/100] Batch 1250/1875                 Loss Disc: 0.3759, Loss Gen: 2.2414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [38/100] Batch 0/1875                 Loss Disc: 0.4486, Loss Gen: 2.3436\n",
      "Epoch [38/100] Batch 625/1875                 Loss Disc: 0.3415, Loss Gen: 2.4139\n",
      "Epoch [38/100] Batch 1250/1875                 Loss Disc: 0.5137, Loss Gen: 1.7538\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [39/100] Batch 0/1875                 Loss Disc: 0.4553, Loss Gen: 2.1225\n",
      "Epoch [39/100] Batch 625/1875                 Loss Disc: 0.4143, Loss Gen: 2.5332\n",
      "Epoch [39/100] Batch 1250/1875                 Loss Disc: 0.4762, Loss Gen: 1.4740\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [40/100] Batch 0/1875                 Loss Disc: 0.3332, Loss Gen: 2.4069\n",
      "Epoch [40/100] Batch 625/1875                 Loss Disc: 0.2766, Loss Gen: 2.5358\n",
      "Epoch [40/100] Batch 1250/1875                 Loss Disc: 0.3686, Loss Gen: 1.9733\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [41/100] Batch 0/1875                 Loss Disc: 0.4905, Loss Gen: 3.0138\n",
      "Epoch [41/100] Batch 625/1875                 Loss Disc: 0.3907, Loss Gen: 2.1511\n",
      "Epoch [41/100] Batch 1250/1875                 Loss Disc: 0.3714, Loss Gen: 2.8553\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [42/100] Batch 0/1875                 Loss Disc: 0.5422, Loss Gen: 1.6525\n",
      "Epoch [42/100] Batch 625/1875                 Loss Disc: 0.4912, Loss Gen: 1.8113\n",
      "Epoch [42/100] Batch 1250/1875                 Loss Disc: 0.5642, Loss Gen: 2.0822\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [43/100] Batch 0/1875                 Loss Disc: 0.4300, Loss Gen: 1.5996\n",
      "Epoch [43/100] Batch 625/1875                 Loss Disc: 0.4199, Loss Gen: 1.9625\n",
      "Epoch [43/100] Batch 1250/1875                 Loss Disc: 0.3721, Loss Gen: 1.6364\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [44/100] Batch 0/1875                 Loss Disc: 0.5731, Loss Gen: 1.8349\n",
      "Epoch [44/100] Batch 625/1875                 Loss Disc: 0.4856, Loss Gen: 1.5248\n",
      "Epoch [44/100] Batch 1250/1875                 Loss Disc: 0.3634, Loss Gen: 2.2550\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [45/100] Batch 0/1875                 Loss Disc: 0.5118, Loss Gen: 1.6259\n",
      "Epoch [45/100] Batch 625/1875                 Loss Disc: 0.4112, Loss Gen: 1.9798\n",
      "Epoch [45/100] Batch 1250/1875                 Loss Disc: 0.4734, Loss Gen: 2.1176\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [46/100] Batch 0/1875                 Loss Disc: 0.5527, Loss Gen: 2.1069\n",
      "Epoch [46/100] Batch 625/1875                 Loss Disc: 0.4194, Loss Gen: 1.6427\n",
      "Epoch [46/100] Batch 1250/1875                 Loss Disc: 0.3809, Loss Gen: 2.1046\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [47/100] Batch 0/1875                 Loss Disc: 0.5069, Loss Gen: 1.7817\n",
      "Epoch [47/100] Batch 625/1875                 Loss Disc: 0.4137, Loss Gen: 1.5830\n",
      "Epoch [47/100] Batch 1250/1875                 Loss Disc: 0.3592, Loss Gen: 1.7609\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [48/100] Batch 0/1875                 Loss Disc: 0.4187, Loss Gen: 2.4797\n",
      "Epoch [48/100] Batch 625/1875                 Loss Disc: 0.5751, Loss Gen: 1.8119\n",
      "Epoch [48/100] Batch 1250/1875                 Loss Disc: 0.3351, Loss Gen: 2.1611\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [49/100] Batch 0/1875                 Loss Disc: 0.2974, Loss Gen: 2.1175\n",
      "Epoch [49/100] Batch 625/1875                 Loss Disc: 0.5808, Loss Gen: 1.8139\n",
      "Epoch [49/100] Batch 1250/1875                 Loss Disc: 0.3361, Loss Gen: 1.8829\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [50/100] Batch 0/1875                 Loss Disc: 0.4391, Loss Gen: 2.8525\n",
      "Epoch [50/100] Batch 625/1875                 Loss Disc: 0.4426, Loss Gen: 2.2858\n",
      "Epoch [50/100] Batch 1250/1875                 Loss Disc: 0.3528, Loss Gen: 1.4057\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [51/100] Batch 0/1875                 Loss Disc: 0.3510, Loss Gen: 2.1208\n",
      "Epoch [51/100] Batch 625/1875                 Loss Disc: 0.3631, Loss Gen: 1.7327\n",
      "Epoch [51/100] Batch 1250/1875                 Loss Disc: 0.2434, Loss Gen: 2.1481\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [52/100] Batch 0/1875                 Loss Disc: 0.2630, Loss Gen: 2.7607\n",
      "Epoch [52/100] Batch 625/1875                 Loss Disc: 0.2154, Loss Gen: 2.8104\n",
      "Epoch [52/100] Batch 1250/1875                 Loss Disc: 0.3748, Loss Gen: 1.6740\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [53/100] Batch 0/1875                 Loss Disc: 0.4730, Loss Gen: 1.3754\n",
      "Epoch [53/100] Batch 625/1875                 Loss Disc: 0.2645, Loss Gen: 2.4834\n",
      "Epoch [53/100] Batch 1250/1875                 Loss Disc: 0.4664, Loss Gen: 2.0205\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [54/100] Batch 0/1875                 Loss Disc: 0.2754, Loss Gen: 2.4913\n",
      "Epoch [54/100] Batch 625/1875                 Loss Disc: 0.4769, Loss Gen: 2.0029\n",
      "Epoch [54/100] Batch 1250/1875                 Loss Disc: 0.3921, Loss Gen: 2.0455\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [55/100] Batch 0/1875                 Loss Disc: 0.3993, Loss Gen: 1.3097\n",
      "Epoch [55/100] Batch 625/1875                 Loss Disc: 0.2935, Loss Gen: 1.9571\n",
      "Epoch [55/100] Batch 1250/1875                 Loss Disc: 0.3993, Loss Gen: 1.8780\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [56/100] Batch 0/1875                 Loss Disc: 0.3492, Loss Gen: 1.8806\n",
      "Epoch [56/100] Batch 625/1875                 Loss Disc: 0.3237, Loss Gen: 2.2069\n",
      "Epoch [56/100] Batch 1250/1875                 Loss Disc: 0.3616, Loss Gen: 2.1897\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [57/100] Batch 0/1875                 Loss Disc: 0.3972, Loss Gen: 2.1602\n",
      "Epoch [57/100] Batch 625/1875                 Loss Disc: 0.3713, Loss Gen: 1.8628\n",
      "Epoch [57/100] Batch 1250/1875                 Loss Disc: 0.4551, Loss Gen: 2.0994\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [58/100] Batch 0/1875                 Loss Disc: 0.3299, Loss Gen: 2.0827\n",
      "Epoch [58/100] Batch 625/1875                 Loss Disc: 0.3162, Loss Gen: 2.1967\n",
      "Epoch [58/100] Batch 1250/1875                 Loss Disc: 0.3665, Loss Gen: 2.8103\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [59/100] Batch 0/1875                 Loss Disc: 0.5098, Loss Gen: 1.6669\n",
      "Epoch [59/100] Batch 625/1875                 Loss Disc: 0.2546, Loss Gen: 2.1345\n",
      "Epoch [59/100] Batch 1250/1875                 Loss Disc: 0.3985, Loss Gen: 2.0514\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [60/100] Batch 0/1875                 Loss Disc: 0.3035, Loss Gen: 1.9398\n",
      "Epoch [60/100] Batch 625/1875                 Loss Disc: 0.4233, Loss Gen: 1.4531\n",
      "Epoch [60/100] Batch 1250/1875                 Loss Disc: 0.4006, Loss Gen: 2.0967\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [61/100] Batch 0/1875                 Loss Disc: 0.3696, Loss Gen: 2.1651\n",
      "Epoch [61/100] Batch 625/1875                 Loss Disc: 0.4517, Loss Gen: 2.3821\n",
      "Epoch [61/100] Batch 1250/1875                 Loss Disc: 0.5208, Loss Gen: 1.7267\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [62/100] Batch 0/1875                 Loss Disc: 0.3500, Loss Gen: 1.8102\n",
      "Epoch [62/100] Batch 625/1875                 Loss Disc: 0.4316, Loss Gen: 2.1121\n",
      "Epoch [62/100] Batch 1250/1875                 Loss Disc: 0.3993, Loss Gen: 1.8985\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [63/100] Batch 0/1875                 Loss Disc: 0.4295, Loss Gen: 2.0408\n",
      "Epoch [63/100] Batch 625/1875                 Loss Disc: 0.3950, Loss Gen: 1.6683\n",
      "Epoch [63/100] Batch 1250/1875                 Loss Disc: 0.2482, Loss Gen: 2.2067\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [64/100] Batch 0/1875                 Loss Disc: 0.4342, Loss Gen: 1.7469\n",
      "Epoch [64/100] Batch 625/1875                 Loss Disc: 0.4528, Loss Gen: 1.8443\n",
      "Epoch [64/100] Batch 1250/1875                 Loss Disc: 0.3371, Loss Gen: 3.0768\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [65/100] Batch 0/1875                 Loss Disc: 0.3563, Loss Gen: 1.4316\n",
      "Epoch [65/100] Batch 625/1875                 Loss Disc: 0.2799, Loss Gen: 1.9428\n",
      "Epoch [65/100] Batch 1250/1875                 Loss Disc: 0.3994, Loss Gen: 1.9144\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [66/100] Batch 0/1875                 Loss Disc: 0.3487, Loss Gen: 2.5545\n",
      "Epoch [66/100] Batch 625/1875                 Loss Disc: 0.3505, Loss Gen: 2.4132\n",
      "Epoch [66/100] Batch 1250/1875                 Loss Disc: 0.4729, Loss Gen: 2.6318\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [67/100] Batch 0/1875                 Loss Disc: 0.3902, Loss Gen: 2.2934\n",
      "Epoch [67/100] Batch 625/1875                 Loss Disc: 0.3894, Loss Gen: 2.4155\n",
      "Epoch [67/100] Batch 1250/1875                 Loss Disc: 0.3977, Loss Gen: 1.9758\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [68/100] Batch 0/1875                 Loss Disc: 0.3437, Loss Gen: 2.1005\n",
      "Epoch [68/100] Batch 625/1875                 Loss Disc: 0.3545, Loss Gen: 2.0344\n",
      "Epoch [68/100] Batch 1250/1875                 Loss Disc: 0.3217, Loss Gen: 2.7124\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [69/100] Batch 0/1875                 Loss Disc: 0.4181, Loss Gen: 1.9573\n",
      "Epoch [69/100] Batch 625/1875                 Loss Disc: 0.5483, Loss Gen: 1.4393\n",
      "Epoch [69/100] Batch 1250/1875                 Loss Disc: 0.3362, Loss Gen: 2.2434\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [70/100] Batch 0/1875                 Loss Disc: 0.3772, Loss Gen: 2.2829\n",
      "Epoch [70/100] Batch 625/1875                 Loss Disc: 0.3399, Loss Gen: 2.0599\n",
      "Epoch [70/100] Batch 1250/1875                 Loss Disc: 0.3023, Loss Gen: 2.3625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [71/100] Batch 0/1875                 Loss Disc: 0.4661, Loss Gen: 1.5515\n",
      "Epoch [71/100] Batch 625/1875                 Loss Disc: 0.5014, Loss Gen: 2.1259\n",
      "Epoch [71/100] Batch 1250/1875                 Loss Disc: 0.3518, Loss Gen: 2.9102\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [72/100] Batch 0/1875                 Loss Disc: 0.4013, Loss Gen: 2.6919\n",
      "Epoch [72/100] Batch 625/1875                 Loss Disc: 0.2861, Loss Gen: 1.4615\n",
      "Epoch [72/100] Batch 1250/1875                 Loss Disc: 0.3730, Loss Gen: 2.6948\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [73/100] Batch 0/1875                 Loss Disc: 0.3626, Loss Gen: 1.8629\n",
      "Epoch [73/100] Batch 625/1875                 Loss Disc: 0.3981, Loss Gen: 1.7902\n",
      "Epoch [73/100] Batch 1250/1875                 Loss Disc: 0.3704, Loss Gen: 2.1656\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [74/100] Batch 0/1875                 Loss Disc: 0.3159, Loss Gen: 2.2650\n",
      "Epoch [74/100] Batch 625/1875                 Loss Disc: 0.3890, Loss Gen: 2.1038\n",
      "Epoch [74/100] Batch 1250/1875                 Loss Disc: 0.4698, Loss Gen: 2.6048\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [75/100] Batch 0/1875                 Loss Disc: 0.3467, Loss Gen: 2.4028\n",
      "Epoch [75/100] Batch 625/1875                 Loss Disc: 0.2975, Loss Gen: 2.2969\n",
      "Epoch [75/100] Batch 1250/1875                 Loss Disc: 0.2737, Loss Gen: 2.6213\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [76/100] Batch 0/1875                 Loss Disc: 0.4463, Loss Gen: 2.1351\n",
      "Epoch [76/100] Batch 625/1875                 Loss Disc: 0.3800, Loss Gen: 2.0276\n",
      "Epoch [76/100] Batch 1250/1875                 Loss Disc: 0.3303, Loss Gen: 2.2240\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [77/100] Batch 0/1875                 Loss Disc: 0.3856, Loss Gen: 2.1744\n",
      "Epoch [77/100] Batch 625/1875                 Loss Disc: 0.3478, Loss Gen: 1.9999\n",
      "Epoch [77/100] Batch 1250/1875                 Loss Disc: 0.4447, Loss Gen: 2.6471\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [78/100] Batch 0/1875                 Loss Disc: 0.3677, Loss Gen: 2.3595\n",
      "Epoch [78/100] Batch 625/1875                 Loss Disc: 0.3683, Loss Gen: 3.0637\n",
      "Epoch [78/100] Batch 1250/1875                 Loss Disc: 0.2994, Loss Gen: 2.3314\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [79/100] Batch 0/1875                 Loss Disc: 0.3168, Loss Gen: 2.1929\n",
      "Epoch [79/100] Batch 625/1875                 Loss Disc: 0.3224, Loss Gen: 2.5760\n",
      "Epoch [79/100] Batch 1250/1875                 Loss Disc: 0.3179, Loss Gen: 2.2672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [80/100] Batch 0/1875                 Loss Disc: 0.3090, Loss Gen: 2.4071\n",
      "Epoch [80/100] Batch 625/1875                 Loss Disc: 0.2903, Loss Gen: 2.5258\n",
      "Epoch [80/100] Batch 1250/1875                 Loss Disc: 0.3883, Loss Gen: 2.1482\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [81/100] Batch 0/1875                 Loss Disc: 0.3195, Loss Gen: 2.5149\n",
      "Epoch [81/100] Batch 625/1875                 Loss Disc: 0.4581, Loss Gen: 1.4318\n",
      "Epoch [81/100] Batch 1250/1875                 Loss Disc: 0.3397, Loss Gen: 2.2261\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [82/100] Batch 0/1875                 Loss Disc: 0.4721, Loss Gen: 2.2063\n",
      "Epoch [82/100] Batch 625/1875                 Loss Disc: 0.3193, Loss Gen: 1.8716\n",
      "Epoch [82/100] Batch 1250/1875                 Loss Disc: 0.3487, Loss Gen: 2.2952\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [83/100] Batch 0/1875                 Loss Disc: 0.4286, Loss Gen: 2.9271\n",
      "Epoch [83/100] Batch 625/1875                 Loss Disc: 0.3148, Loss Gen: 2.5130\n",
      "Epoch [83/100] Batch 1250/1875                 Loss Disc: 0.3126, Loss Gen: 1.9002\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [84/100] Batch 0/1875                 Loss Disc: 0.5051, Loss Gen: 2.2105\n",
      "Epoch [84/100] Batch 625/1875                 Loss Disc: 0.4519, Loss Gen: 1.8125\n",
      "Epoch [84/100] Batch 1250/1875                 Loss Disc: 0.2975, Loss Gen: 2.7527\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [85/100] Batch 0/1875                 Loss Disc: 0.2798, Loss Gen: 2.8643\n",
      "Epoch [85/100] Batch 625/1875                 Loss Disc: 0.3487, Loss Gen: 2.0732\n",
      "Epoch [85/100] Batch 1250/1875                 Loss Disc: 0.4024, Loss Gen: 1.7782\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [86/100] Batch 0/1875                 Loss Disc: 0.4377, Loss Gen: 1.4145\n",
      "Epoch [86/100] Batch 625/1875                 Loss Disc: 0.4477, Loss Gen: 2.1537\n",
      "Epoch [86/100] Batch 1250/1875                 Loss Disc: 0.4145, Loss Gen: 2.4252\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [87/100] Batch 0/1875                 Loss Disc: 0.4475, Loss Gen: 1.6861\n",
      "Epoch [87/100] Batch 625/1875                 Loss Disc: 0.2597, Loss Gen: 2.1092\n",
      "Epoch [87/100] Batch 1250/1875                 Loss Disc: 0.3929, Loss Gen: 2.0841\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [88/100] Batch 0/1875                 Loss Disc: 0.3245, Loss Gen: 2.2481\n",
      "Epoch [88/100] Batch 625/1875                 Loss Disc: 0.4133, Loss Gen: 2.5512\n",
      "Epoch [88/100] Batch 1250/1875                 Loss Disc: 0.3447, Loss Gen: 2.0600\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [89/100] Batch 0/1875                 Loss Disc: 0.4255, Loss Gen: 1.7526\n",
      "Epoch [89/100] Batch 625/1875                 Loss Disc: 0.2358, Loss Gen: 2.6134\n",
      "Epoch [89/100] Batch 1250/1875                 Loss Disc: 0.3838, Loss Gen: 2.1829\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [90/100] Batch 0/1875                 Loss Disc: 0.3230, Loss Gen: 2.0752\n",
      "Epoch [90/100] Batch 625/1875                 Loss Disc: 0.2337, Loss Gen: 2.3462\n",
      "Epoch [90/100] Batch 1250/1875                 Loss Disc: 0.2237, Loss Gen: 2.4346\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [91/100] Batch 0/1875                 Loss Disc: 0.4225, Loss Gen: 2.1732\n",
      "Epoch [91/100] Batch 625/1875                 Loss Disc: 0.4530, Loss Gen: 2.0452\n",
      "Epoch [91/100] Batch 1250/1875                 Loss Disc: 0.3157, Loss Gen: 2.5489\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [92/100] Batch 0/1875                 Loss Disc: 0.3555, Loss Gen: 2.4101\n",
      "Epoch [92/100] Batch 625/1875                 Loss Disc: 0.3039, Loss Gen: 2.3685\n",
      "Epoch [92/100] Batch 1250/1875                 Loss Disc: 0.4554, Loss Gen: 1.6191\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [93/100] Batch 0/1875                 Loss Disc: 0.3310, Loss Gen: 1.7744\n",
      "Epoch [93/100] Batch 625/1875                 Loss Disc: 0.3644, Loss Gen: 2.4995\n",
      "Epoch [93/100] Batch 1250/1875                 Loss Disc: 0.3256, Loss Gen: 2.7594\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [94/100] Batch 0/1875                 Loss Disc: 0.4287, Loss Gen: 2.4596\n",
      "Epoch [94/100] Batch 625/1875                 Loss Disc: 0.4751, Loss Gen: 1.8381\n",
      "Epoch [94/100] Batch 1250/1875                 Loss Disc: 0.4584, Loss Gen: 2.0517\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [95/100] Batch 0/1875                 Loss Disc: 0.2984, Loss Gen: 2.0762\n",
      "Epoch [95/100] Batch 625/1875                 Loss Disc: 0.5408, Loss Gen: 1.4024\n",
      "Epoch [95/100] Batch 1250/1875                 Loss Disc: 0.3856, Loss Gen: 2.2412\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [96/100] Batch 0/1875                 Loss Disc: 0.4576, Loss Gen: 2.3839\n",
      "Epoch [96/100] Batch 625/1875                 Loss Disc: 0.3528, Loss Gen: 2.3413\n",
      "Epoch [96/100] Batch 1250/1875                 Loss Disc: 0.4559, Loss Gen: 2.4055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [97/100] Batch 0/1875                 Loss Disc: 0.2827, Loss Gen: 2.4512\n",
      "Epoch [97/100] Batch 625/1875                 Loss Disc: 0.4304, Loss Gen: 2.9928\n",
      "Epoch [97/100] Batch 1250/1875                 Loss Disc: 0.2818, Loss Gen: 2.5149\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [98/100] Batch 0/1875                 Loss Disc: 0.3481, Loss Gen: 1.9157\n",
      "Epoch [98/100] Batch 625/1875                 Loss Disc: 0.3254, Loss Gen: 1.9489\n",
      "Epoch [98/100] Batch 1250/1875                 Loss Disc: 0.3489, Loss Gen: 2.3824\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [99/100] Batch 0/1875                 Loss Disc: 0.3495, Loss Gen: 2.6165\n",
      "Epoch [99/100] Batch 625/1875                 Loss Disc: 0.2642, Loss Gen: 2.9970\n",
      "Epoch [99/100] Batch 1250/1875                 Loss Disc: 0.2371, Loss Gen: 3.0999\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nStarted Training and visualization...\")\n",
    "fixedNoise = torch.randn(config.batchSize, config.zDim).to(config.device)  # Define fixed noise for visualization\n",
    "step = 0  # Initialize step counter\n",
    "\n",
    "for epoch in range(config.numEpochs):\n",
    "    print('-' * 80)\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.view(-1, 784).to(config.device)\n",
    "        batch_size = real.shape[0]\n",
    "        noise = torch.randn(batch_size, config.zDim).to(config.device)\n",
    "        fake = generator(noise)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        discReal = discriminator(real).view(-1)\n",
    "        discFake = discriminator(fake.detach()).view(-1)\n",
    "        \n",
    "        lossDreal = criterion(discReal, torch.ones_like(discReal))\n",
    "        lossDfake = criterion(discFake, torch.zeros_like(discFake))\n",
    "        \n",
    "        lossD = (lossDreal + lossDfake) / 2\n",
    "        discriminator.zero_grad()\n",
    "        lossD.backward()\n",
    "        optDisc.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        output = discriminator(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        generator.zero_grad()\n",
    "        lossG.backward()\n",
    "        optGen.step()\n",
    "        \n",
    "        if batch_idx % config.logstep == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{config.numEpochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                Loss Disc: {lossD:.4f}, Loss Gen: {lossG:.4f}\"\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                # Generate noise via Generator\n",
    "                fake = generator(fixedNoise).reshape(-1, 1, 28, 28)\n",
    "                # Get real data\n",
    "                data = real.reshape(-1, 1, 28, 28)\n",
    "                # Plot the grid\n",
    "                imgGridFake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                imgGridReal = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                writerFake.add_image(\"MNIST Fake Images\", imgGridFake, global_step=step)\n",
    "                writerReal.add_image(\"MNIST Real Images\", imgGridReal, global_step=step)\n",
    "\n",
    "                writerFake.flush()\n",
    "                writerReal.flush()\n",
    "\n",
    "            step += 1  # Increment step counter\n",
    "\n",
    "writerFake.close()\n",
    "writerReal.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19db34c-0970-435c-b362-17cdf3276d98",
   "metadata": {},
   "source": [
    "# run in Anaconda Prompt\n",
    "tensorboard --logdir=\"C:\\Users\\raksh\\OneDrive\\Documents\\DL_Writer\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
